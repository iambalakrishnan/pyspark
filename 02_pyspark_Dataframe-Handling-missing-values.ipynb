{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd331d6",
   "metadata": {},
   "source": [
    "## Pyspark Handling Missing Values\n",
    "\n",
    "- Dropping columns\n",
    "- Dropping Rowns\n",
    "- Various Parameter in Dropping functionalities\n",
    "- Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5af484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74bcce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b52e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/test2.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc719b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53cf0a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        10| 30000|\n",
      "|  30|         8| 25000|\n",
      "|  29|         4| 20000|\n",
      "|  24|         3| 20000|\n",
      "|  21|         1| 15000|\n",
      "|  23|         2| 18000|\n",
      "|null|      null| 40000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the columns\n",
    "\n",
    "df.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e96ffdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e6d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop null values rows\n",
    "\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7298920",
   "metadata": {},
   "source": [
    "Signature:\n",
    "<code>\n",
    "df.na.drop( how: str = 'any',\n",
    "thresh: Optional[int] = None,\n",
    "subset: Union[str, Tuple[str, ...], List[str], NoneType] = None,\n",
    ") -> pyspark.sql.dataframe.DataFrame\n",
    "</code>\n",
    "\n",
    "\n",
    "Docstring:\n",
    "Returns a new :class:`DataFrame` omitting rows with null values.\n",
    ":func:`DataFrame.dropna` and :func:`DataFrameNaFunctions.drop` are aliases of each other.\n",
    "\n",
    ".. versionadded:: 1.3.1\n",
    "\n",
    ".. versionchanged:: 3.4.0\n",
    "    Supports Spark Connect.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "how : str, optional\n",
    "    'any' or 'all'.\n",
    "    If 'any', drop a row if it contains any nulls.\n",
    "    If 'all', drop a row only if all its values are null.\n",
    "thresh: int, optional\n",
    "    default None\n",
    "    If specified, drop rows that have less than `thresh` non-null values.\n",
    "    This overwrites the `how` parameter.\n",
    "subset : str, tuple or list, optional\n",
    "    optional list of column names to consider.\n",
    "\n",
    "Returns\n",
    "-------\n",
    ":class:`DataFrame`\n",
    "    DataFrame with null only rows excluded.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "<code>\n",
    ">>>from pyspark.sql import Row\n",
    ">>> df = spark.createDataFrame([\n",
    "...     Row(age=10, height=80, name=\"Alice\"),\n",
    "...     Row(age=5, height=None, name=\"Bob\"),\n",
    "...     Row(age=None, height=None, name=\"Tom\"),\n",
    "...     Row(age=None, height=None, name=None),\n",
    "... ])\n",
    ">>> df.na.drop().show()\n",
    "+---+------+-----+\n",
    "|age|height| name|\n",
    "+---+------+-----+\n",
    "| 10|    80|Alice|\n",
    "+---+------+-----+\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d056ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how ='all' -> all values in column should be null then it will remove the entire row\n",
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04a90bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Threshold -> if minimum threshold non null values should be present to avoid removing the column\n",
    "# thresh=2 -> 2 non null values should be there to avoid deleing the row\n",
    "\n",
    "df.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fbc3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any', thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7edb57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any', thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29b9ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#subset -> if any null vales present in the specififed column then the entire row wil be removed\n",
    "\n",
    "df.na.drop(how='any', subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4154d66",
   "metadata": {},
   "source": [
    "Signature:\n",
    "```\n",
    "df.na.fill(\n",
    "    value: Union[ForwardRef('LiteralType'), Dict[str, ForwardRef('LiteralType')]],\n",
    "    subset: Optional[List[str]] = None,\n",
    ") -> pyspark.sql.dataframe.DataFrame\n",
    "```    \n",
    "</code>\n",
    "Docstring:\n",
    "Replace null values, alias for ``na.fill()``.\n",
    ":func:`DataFrame.fillna` and :func:`DataFrameNaFunctions.fill` are aliases of each other.\n",
    "\n",
    ".. versionadded:: 1.3.1\n",
    "\n",
    ".. versionchanged:: 3.4.0\n",
    "    Supports Spark Connect.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "value : int, float, string, bool or dict\n",
    "    Value to replace null values with.\n",
    "    If the value is a dict, then `subset` is ignored and `value` must be a mapping\n",
    "    from column name (string) to replacement value. The replacement value must be\n",
    "    an int, float, boolean, or string.\n",
    "subset : str, tuple or list, optional\n",
    "    optional list of column names to consider.\n",
    "    Columns specified in subset that do not have matching data types are ignored.\n",
    "    For example, if `value` is a string, and subset contains a non-string column,\n",
    "    then the non-string column is simply ignored.\n",
    "\n",
    "Returns\n",
    "-------\n",
    ":class:`DataFrame`\n",
    "    DataFrame with replaced null values.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "```\n",
    ">>> df = spark.createDataFrame([\n",
    "...     (10, 80.5, \"Alice\", None),\n",
    "...     (5, None, \"Bob\", None),\n",
    "...     (None, None, \"Tom\", None),\n",
    "...     (None, None, None, True)],\n",
    "...     schema=[\"age\", \"height\", \"name\", \"bool\"])\n",
    "Fill all null values with 50 for numeric columns.\n",
    ">>>df.na.fill(50).show()\n",
    "\n",
    "+---+------+-----+----+\n",
    "|age|height| name|bool|\n",
    "+---+------+-----+----+\n",
    "| 10|  80.5|Alice|null|\n",
    "|  5|  50.0|  Bob|null|\n",
    "| 50|  50.0|  Tom|null|\n",
    "| 50|  50.0| null|true|\n",
    "+---+------+-----+----+\n",
    "Fill all null values with ``False`` for boolean columns.\n",
    "    \n",
    ">>> df.na.fill(False).show()\n",
    "+----+------+-----+-----+\n",
    "| age|height| name| bool|\n",
    "+----+------+-----+-----+\n",
    "|  10|  80.5|Alice|false|\n",
    "|   5|  null|  Bob|false|\n",
    "|null|  null|  Tom|false|\n",
    "|null|  null| null| true|\n",
    "+----+------+-----+-----+\n",
    "    \n",
    "Fill all null values with to 50 and \"unknown\" for 'age' and 'name' column respectively.\n",
    "    \n",
    ">>> df.na.fill({'age': 50, 'name': 'unknown'}).show()\n",
    "+---+------+-------+----+\n",
    "|age|height|   name|bool|\n",
    "+---+------+-------+----+\n",
    "| 10|  80.5|  Alice|null|\n",
    "|  5|  null|    Bob|null|\n",
    "| 50|  null|    Tom|null|\n",
    "| 50|  null|unknown|true|\n",
    "+---+------+-------+----+\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58159135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Mahesh| 50|        50| 40000|\n",
      "|     null| 34|        10| 38000|\n",
      "|     null| 36|        50|  null|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(value=50,subset=[\"Experience\",'age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5d98ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "335bee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "inputCols=['age','Experience','Salary'],\n",
    "outputCols = [f\"{c} imputer\" for c in ['age','Experience','Salary']]).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "338ff9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|     Name| age|Experience|Salary|age imputer|Experience imputer|Salary imputer|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
      "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
      "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
      "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
      "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
      "|   Mahesh|null|      null| 40000|         28|                 5|         40000|\n",
      "|     null|  34|        10| 38000|         34|                10|         38000|\n",
      "|     null|  36|      null|  null|         36|                 5|         25750|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imputation cols to df\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a5326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
